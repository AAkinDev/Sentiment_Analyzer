{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[K     |████████████████████████████████| 244 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.9.0 in /Users/bolade/opt/anaconda3/lib/python3.9/site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/bolade/opt/anaconda3/lib/python3.9/site-packages (from python-docx) (4.6.3)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73d6bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/bolade/opt/anaconda3/lib/python3.9/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cf5834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bolade/env/sentiment_analysis_projects/reddit_sentiment_analysis/Reddit_Sentiment_Readme.docx'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Create a new Word document\n",
    "doc = Document()\n",
    "\n",
    "# Add title\n",
    "doc.add_heading('📈 Reddit Sentiment Analysis with Pipedream & Streamlit', level=1)\n",
    "\n",
    "# Add project overview\n",
    "doc.add_paragraph(\"🚀 Automated Reddit sentiment analysis using Pipedream for data collection, Google Sheets/PostgreSQL for storage, and Streamlit for interactive visualization.\")\n",
    "\n",
    "doc.add_heading('🛠️ Project Overview', level=2)\n",
    "doc.add_paragraph(\"This project tracks sentiment on Reddit discussions in real-time using Pipedream automation. \"\n",
    "                  \"The data is processed using NLP sentiment analysis, stored in Google Sheets/PostgreSQL, and visualized in a Streamlit dashboard.\")\n",
    "\n",
    "doc.add_heading('💡 Use Cases', level=2)\n",
    "doc.add_paragraph(\"✅ Track public sentiment on AI, tech trends, crypto, or politics\\n\"\n",
    "                  \"✅ Monitor brand reputation based on subreddit discussions\\n\"\n",
    "                  \"✅ Automate data collection for continuous analysis\")\n",
    "\n",
    "doc.add_heading('📈 Architecture & Tech Stack', level=2)\n",
    "tech_stack_table = doc.add_table(rows=1, cols=2)\n",
    "hdr_cells = tech_stack_table.rows[0].cells\n",
    "hdr_cells[0].text = \"Component\"\n",
    "hdr_cells[1].text = \"Technology Used\"\n",
    "\n",
    "tech_stack = [\n",
    "    (\"Data Collection\", \"🛠️ Pipedream (Reddit API)\"),\n",
    "    (\"Sentiment Analysis\", \"🧠 TextBlob, Vader (NLP)\"),\n",
    "    (\"Storage\", \"📊 Google Sheets / PostgreSQL\"),\n",
    "    (\"Visualization\", \"📈 Streamlit, Plotly\"),\n",
    "    (\"Deployment\", \"🌐 Streamlit Cloud / Hugging Face Spaces\")\n",
    "]\n",
    "\n",
    "for item in tech_stack:\n",
    "    row_cells = tech_stack_table.add_row().cells\n",
    "    row_cells[0].text = item[0]\n",
    "    row_cells[1].text = item[1]\n",
    "\n",
    "doc.add_heading('🛠️ Features', level=2)\n",
    "doc.add_paragraph(\"✅ Serverless automation with Pipedream\\n\"\n",
    "                  \"✅ Reddit API Integration (PRAW, REST API)\\n\"\n",
    "                  \"✅ Sentiment analysis using NLP (TextBlob, Vader)\\n\"\n",
    "                  \"✅ Data storage in Google Sheets/PostgreSQL\\n\"\n",
    "                  \"✅ Interactive Streamlit Dashboard\")\n",
    "\n",
    "doc.add_heading('🔄 Workflow Breakdown', level=2)\n",
    "\n",
    "doc.add_heading('1️⃣ Automating Data Collection with Pipedream', level=3)\n",
    "doc.add_paragraph('''\n",
    "import { axios } from \"@pipedream/platform\";\n",
    "\n",
    "export default defineComponent({\n",
    "  async run({ steps }) {\n",
    "    const redditUrl = \"https://www.reddit.com/r/technology/hot.json?limit=50\";\n",
    "    const response = await axios(this, { method: \"GET\", url: redditUrl });\n",
    "\n",
    "    return response.data.data.children.map(post => ({\n",
    "      title: post.data.title,\n",
    "      upvotes: post.data.ups\n",
    "    }));\n",
    "  }\n",
    "});\n",
    "''')\n",
    "\n",
    "doc.add_heading('2️⃣ Storing Data in Google Sheets / PostgreSQL', level=3)\n",
    "doc.add_paragraph(\"#### Option 1: Google Sheets\\n- Pipedream sends the processed Reddit data to Google Sheets using the Google Sheets API.\\n\\n#### Option 2: PostgreSQL Database\")\n",
    "doc.add_paragraph('''\n",
    "CREATE TABLE reddit_sentiment (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    post_title TEXT,\n",
    "    sentiment_score FLOAT,\n",
    "    upvotes INT,\n",
    "    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "''')\n",
    "\n",
    "doc.add_heading('3️⃣ Visualization with Streamlit', level=3)\n",
    "doc.add_paragraph('''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "st.title(\"📊 Reddit Sentiment Analysis\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"reddit_sentiment.csv\")\n",
    "\n",
    "# Sentiment Distribution Plot\n",
    "fig = px.histogram(df, x=\"Sentiment\", nbins=20, title=\"Sentiment Analysis\")\n",
    "st.plotly_chart(fig)\n",
    "''')\n",
    "\n",
    "doc.add_heading('👨‍💻 How to Run This Project', level=2)\n",
    "\n",
    "steps = [\n",
    "    (\"1️⃣ Clone the Repository\", \"git clone https://github.com/yourusername/reddit-sentiment-analysis.git\\ncd reddit-sentiment-analysis\"),\n",
    "    (\"2️⃣ Install Dependencies\", \"pip install praw textblob pandas plotly streamlit\"),\n",
    "    (\"3️⃣ Set Up Environment Variables\", \"Create a `.env` file and add:\\nCLIENT_ID=your_reddit_client_id\\nCLIENT_SECRET=your_reddit_client_secret\\nUSER_AGENT=MyRedditSentimentApp\"),\n",
    "    (\"4️⃣ Run Data Collection Script\", \"python fetch_reddit_data.py\"),\n",
    "    (\"5️⃣ Run Streamlit Dashboard\", \"streamlit run app.py\")\n",
    "]\n",
    "\n",
    "for step in steps:\n",
    "    doc.add_heading(step[0], level=3)\n",
    "    doc.add_paragraph(step[1])\n",
    "\n",
    "doc.add_heading('📈 Results & Insights', level=2)\n",
    "doc.add_paragraph(\"Sample Insights from Reddit Analysis:\\n\"\n",
    "                  \"- AI-related posts received highly positive sentiment.\\n\"\n",
    "                  \"- Crypto-related discussions were more polarized.\\n\"\n",
    "                  \"- Negative sentiment spikes corresponded with controversial news.\")\n",
    "\n",
    "doc.add_heading('💪 Future Improvements', level=2)\n",
    "doc.add_paragraph(\"✅ Train a custom ML model for more accurate sentiment classification\\n\"\n",
    "                  \"✅ Expand to multiple subreddits to track cross-community sentiment\\n\"\n",
    "                  \"✅ Use Named Entity Recognition (NER) to extract key topics\\n\"\n",
    "                  \"✅ Deploy Streamlit app publicly on Streamlit Cloud / Hugging Face\")\n",
    "\n",
    "doc.add_heading('📚 Contributions', level=2)\n",
    "doc.add_paragraph(\"👥 Contributions are welcome! If you’d like to enhance this project:\\n1. Fork the repo\\n2. Create a new feature branch\\n3. Submit a PR with improvements\")\n",
    "\n",
    "doc.add_heading('💎 License', level=2)\n",
    "doc.add_paragraph(\"📚 MIT License - Feel free to use and modify this project.\")\n",
    "\n",
    "doc.add_heading('📱 Connect With Me', level=2)\n",
    "doc.add_paragraph(\"📺 GitHub: [@yourgithub](https://github.com/yourusername)\\n\"\n",
    "                  \"👤 LinkedIn: [Your Name](https://linkedin.com/in/yourname)\\n\"\n",
    "                  \"🌐 Portfolio: [yourwebsite.com](https://yourwebsite.com)\")\n",
    "\n",
    "# Save the document\n",
    "doc_path = \"/Users/bolade/env/sentiment_analysis_projects/reddit_sentiment_analysis/Reddit_Sentiment_Readme.docx\"\n",
    "doc.save(doc_path)\n",
    "\n",
    "# Provide the download link\n",
    "doc_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729d073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
